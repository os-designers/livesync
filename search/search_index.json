{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"LiveSync","text":"<p>LiveSync is Keras-inspired asynchronous stream processing framework for building real-time media applications. LiveSync provides a flexible layer system for creating both synchronous and asynchronous media processing pipelines.</p>"},{"location":"#why-livesync","title":"Why LiveSync?","text":"<ul> <li>Layer-Based Architecture: Build complex processing pipelines using a Keras-inspired layer system</li> <li>Async-First Design: Built from the ground up for asynchronous stream processing</li> <li>Media Processing: Optimized for real-time audio and video processing</li> <li>Flexible Stream System: Support for both synchronous and asynchronous data flows</li> <li>Remote Processing: Built-in gRPC support for distributed processing</li> </ul>"},{"location":"#get-started","title":"Get Started","text":"<p>New to LiveSync? Follow the Installation Guide to set up your environment and run your first pipeline.</p> <p>For a quick introduction, check out our Quick Start.</p>"},{"location":"#documentation-overview","title":"Documentation Overview","text":"<ul> <li>Getting Started \u2013 Install and set up LiveSync.</li> <li>User Guide \u2013 Learn about core concepts like streams, inputs, layers, and sync.</li> <li>Examples \u2013 Sample pipelines and advanced use cases.</li> </ul>"},{"location":"#get-involved","title":"Get Involved","text":"<p>LiveSync is open-source and actively maintained by OS Designers, Inc.. Join our community, contribute, or report issues on our GitHub repository.</p> <p>\ud83d\udd17 GitHub: os-designers/livesync \ud83d\udcc4 License: MIT</p>"},{"location":"examples/advanced/","title":"Advanced Examples","text":"<p>Building on the basic concepts, let's explore more complex pipelines with media synchronization and stream merging.</p>"},{"location":"examples/advanced/#media-synchronization-pipeline","title":"Media Synchronization Pipeline","text":"<p>This example demonstrates how to build a pipeline that synchronizes video and audio streams with precise timing control.</p>"},{"location":"examples/advanced/#example-synchronized-recording-pipeline","title":"Example: Synchronized Recording Pipeline","text":"<pre><code>import livesync as ls\nfrom livesync import layers\n\n# Create input streams\nx1 = ls.WebcamInput(device_id=1, fps=30)\nx2 = ls.MicrophoneInput(sample_rate=44100, chunk_size=1024)\n\n# Create processing layers\nf1 = layers.DelayLayer(interval=1.0)              # Add 1s delay to audio\nf2 = layers.MediaSyncLayer(\n    buffer_size=1024,\n    max_threshold=0.005                           # 5ms sync threshold\n)\nf3 = layers.MediaRecorderLayer(\n    filename=\"./output.mp4\",\n    fps=30\n)\n\n# Build pipeline\nh = f1(x2)                                        # Delayed audio\nu = layers.Merge([x1, h], how=\"outer\")           # Merge streams\ny = f3(f2(u))                                     # Sync and record\n\n# Create and run pipeline\nsync = ls.Sync(inputs=[x1, x2], outputs=[y])\nwith sync.compile() as runner:\n    runner.run(callback=ls.LoggingCallback())\n</code></pre> <p>This pipeline:</p> <ol> <li>Captures video from webcam and audio from microphone</li> <li>Adds a 1-second delay to the audio stream</li> <li>Merges streams with \"outer\" mode (processes when either stream has data)</li> <li>Synchronizes video and audio within 5ms precision</li> <li>Records the synchronized output to MP4</li> </ol> <pre><code>  \u25cf  (f3): Records synchronized media to MP4 file\n  \u2502\n  \u25cf  (f2): Synchronizes streams within 5ms threshold\n  \u2502\n  \u25cb  (u): Merges streams (processes on any input)\n  \u2502\n  \u25cb\u2500\u2500\u25cf  (waits for either stream)\n  \u2502  \u2502\n  \u2502  \u25cf  (f1): Delays audio by 1 second\n  \u2502  \u2502\n  \u2502  \u25c7  (x2): Microphone input\n  \u2502\n  \u25c7  (x1): Webcam input\n</code></pre>"},{"location":"examples/advanced/#key-concepts","title":"Key Concepts","text":"<ul> <li>Stream Merging: The <code>how=\"outer\"</code> parameter in <code>Merge</code> means the layer processes whenever either input stream has data</li> <li>Media Sync: <code>MediaSyncLayer</code> ensures audio and video stay synchronized within the specified threshold</li> <li>Delay Control: <code>DelayLayer</code> can adjust timing relationships between streams</li> </ul>"},{"location":"examples/advanced/#running-the-example","title":"Running the Example","text":"<p>Save the script as <code>media_sync_recording.py</code> and run:</p> <pre><code>rye run examples/06_media_sync_recording.py\n</code></pre> <p>The pipeline will start capturing synchronized audio and video, saving the result to <code>output.mp4</code>.</p>"},{"location":"examples/basic/","title":"Quick Start","text":"<p>This guide walks you through creating your first LiveSync pipeline for media processing.</p>"},{"location":"examples/basic/#creating-a-simple-video-pipeline","title":"Creating a Simple Video Pipeline","text":"<p>LiveSync uses a graph-based architecture where nodes represent different processing steps. Let's create a simple video processing pipeline.</p>"},{"location":"examples/basic/#example-webcam-recording-pipeline","title":"Example: Webcam Recording Pipeline","text":"<pre><code>import livesync as ls\nfrom livesync import layers\n\n# Create input stream\nx = ls.WebcamInput(name=\"webcam\", device_id=0, fps=30)\n\n# Create processing layers\nf1 = layers.FpsControl(name=\"frame_rate\", fps=10)\nf2 = layers.VideoRecorder(\n    name=\"video_recorder\",\n    filename=\"./output.mp4\",\n    fps=f1.fps\n)\n\ny = f2(f1(x))\n\n# Create and run pipeline\nsync = ls.Sync(inputs=[x], outputs=[y])\nwith sync.compile() as runner:\n    run = runner.run(callback=ls.LoggingCallback())\n</code></pre> <p>This pipeline:</p> <ol> <li>Captures video from your webcam at 30 FPS</li> <li>Processes it through a frame rate controller to achieve 10 FPS</li> <li>Records the output to a video file</li> </ol> <pre><code>  \u25cf  (f2): Records processed frames to MP4 file\n  \u2502\n  \u25cf  (f1): Controls frame rate of the stream\n  \u2502\n  \u25c7  (x): Captures frames from webcam\n</code></pre>"},{"location":"examples/basic/#running-the-example","title":"Running the Example","text":"<p>Save the script as <code>webcam_fps_control.py</code> and run:</p> <pre><code>rye run examples/04_webcam_fps_control.py\n</code></pre> <p>The pipeline will start capturing from your webcam and save the processed video to <code>output.mp4</code>.</p> <p>Next Steps</p> <ul> <li>Learn about more complex pipelines in the User Guide</li> <li>See more examples in the Examples section</li> </ul>"},{"location":"getting-started/installation/","title":"Installation","text":"<p>LiveSync is a real-time media processing framework that helps you build efficient video and audio pipelines. This guide will walk you through the setup process.</p>"},{"location":"getting-started/installation/#requirements","title":"Requirements","text":"<ul> <li>Python 3.10 or higher</li> <li>FFmpeg (required for media processing)</li> <li>OpenCV (automatically installed with LiveSync)</li> </ul>"},{"location":"getting-started/installation/#installing-ffmpeg","title":"Installing FFmpeg","text":"<p>FFmpeg is required for media processing. Here's how to install it:</p> <p>Windows:</p> <pre><code>choco install ffmpeg\n</code></pre> <p>macOS:</p> <pre><code>brew install ffmpeg\n</code></pre> <p>Linux (Ubuntu/Debian):</p> <pre><code>sudo apt update\nsudo apt install ffmpeg\n</code></pre> <p>Verify FFmpeg installation:</p> <pre><code>ffmpeg -version\n</code></pre>"},{"location":"getting-started/installation/#installing-livesync","title":"Installing LiveSync","text":""},{"location":"getting-started/installation/#option-1-using-rye-recommended","title":"Option 1: Using <code>rye</code> (Recommended)","text":"<pre><code>rye add livesync-io\n</code></pre>"},{"location":"getting-started/installation/#option-2-using-pip","title":"Option 2: Using <code>pip</code>","text":"<pre><code>pip install livesync-io\n</code></pre>"},{"location":"getting-started/installation/#verifying-installation","title":"Verifying Installation","text":"<p>After installation, verify that LiveSync is installed correctly:</p> <pre><code>python -c \"import livesync; print(livesync.__version__)\"\n</code></pre> <p>If the installation was successful, you should see the LiveSync version number.</p> <p>Next Steps Now that LiveSync is installed, check out the Quick Start Guide to create your first processing pipeline.</p>"},{"location":"getting-started/quickstart/","title":"Quick Start","text":"<p>Let's start with a simple example that demonstrates the core concepts of LiveSync.</p>"},{"location":"getting-started/quickstart/#installation","title":"Installation","text":"<pre><code>pip install livesync\n</code></pre>"},{"location":"getting-started/quickstart/#basic-example","title":"Basic Example","text":"<p>Here's a minimal example that shows how LiveSync processes data streams:</p> <pre><code>import livesync as ls\nfrom livesync import layers\n\n# Create two input streams that generate numbers\nx1 = ls.PeriodicConstantInput(2, interval=1.0)    # Generates '2' every second\nx2 = ls.PeriodicConstantInput(4, interval=1.0)    # Generates '4' every second\n\n# Create processing layers\nf1 = layers.Multiply(multiplier=4)                # Multiplies input by 4\nf2 = layers.Multiply(multiplier=4)                # Multiplies input by 4\n\n# Build processing chain\nh1 = f1(x1)                                       # 2 * 4 = 8\nh2 = f2(x2)                                       # 4 * 4 = 16\n\n# Merge streams and process\nu = layers.Merge([h1, h2], how=\"inner\")          # Waits for both inputs\ny = layers.Lambda(\n    function=lambda inputs: inputs[h1.name] * inputs[h2.name]\n)(u)                                             # 8 * 16 = 128\n\n# Run the pipeline\nsync = ls.Sync(inputs=[x1, x2], outputs=[y])\nwith sync.compile() as runner:\n    runner.run(\n        continuous=False,                         # Run once and stop\n        callback=ls.LoggingCallback()\n    )\n</code></pre> <p>This pipeline:</p> <pre><code>  \u25cf  Final output: 128\n  \u2502\n  \u25cf  Multiply merged values\n  \u2502\n  \u25cb  Merge (waits for both inputs)\n  \u2502\n  \u25cb\u2500\u2500\u25cf\n  \u2502  \u2502\n  \u2502  \u25cf  Multiply by 4 (16)\n  \u2502  \u2502\n  \u2502  \u25c7  Input: 4\n  \u2502\n  \u25cf  Multiply by 4 (8)\n  \u2502\n  \u25c7  Input: 2\n</code></pre>"},{"location":"getting-started/quickstart/#understanding-the-flow","title":"Understanding the Flow","text":"<ol> <li>Input Streams: Two periodic inputs generate constant values</li> <li>Processing Layers: Each input is multiplied by 4</li> <li>Merge Operation: Streams are combined using \"inner\" mode (waits for both inputs)</li> <li>Final Processing: Merged values are multiplied together</li> <li>Execution: Pipeline runs once and logs the result</li> </ol>"},{"location":"getting-started/quickstart/#next-steps","title":"Next Steps","text":"<ul> <li>Try more complex examples in Basic Examples</li> <li>Learn about media processing in Advanced Examples</li> <li>Explore core concepts in the User Guide</li> </ul>"},{"location":"user-guide/core-concepts/","title":"Core Concepts","text":"<p>LiveSync is a framework for building real-time media processing pipelines, inspired by Keras. Here's how data flows through the system:</p>"},{"location":"user-guide/core-concepts/#1-streams","title":"1. Streams","text":"<p>Streams are the foundation of LiveSync - they represent flowing data that moves through processing steps:</p> <pre><code>x = WebcamInput(...)  # Source of frames\ny = some_layer(x)     # Processed frames\n</code></pre> <p>Key characteristics:</p> <ul> <li>Asynchronous Flow: Data moves independently through the pipeline</li> <li>Type Safety: Each stream carries specific data types (e.g., VideoFrame, AudioFrame)</li> <li>Backpressure: Automatically manages flow when downstream processing is slower</li> </ul>"},{"location":"user-guide/core-concepts/#2-input-streams","title":"2. Input Streams","text":"<p>Input streams are the data sources that trigger the pipeline:</p> <pre><code># Common input streams\nwebcam = ls.WebcamInput(device_id=0, fps=30)      # Video frames\nmic = ls.MicrophoneInput(sample_rate=44100)       # Audio samples\n</code></pre> <p>Key points:</p> <ul> <li>Trigger Role: Input streams initiate data flow</li> <li>Asynchronous Generation: Continuously produce new data</li> <li>Built-in Controls: Manage frame rates, buffering, etc.</li> </ul>"},{"location":"user-guide/core-concepts/#3-layers","title":"3. Layers","text":"<p>Layers define operations on streams. When you call a layer with a stream as input, it returns a new stream containing the operation to be performed, but no actual processing happens until the pipeline is executed:</p> <pre><code># Processing chain example\nx = ls.WebcamInput(device_id=0)\nprocessed = layers.FpsControl(fps=15)(x)          # Control frame rate\nmerged = layers.Merge([processed, mic])           # Combine streams\nrecorded = layers.MediaRecorder(\"output.mp4\")(merged)\n</code></pre>"},{"location":"user-guide/core-concepts/#4-sync","title":"4. Sync","text":"<p>Sync orchestrates the pipeline by managing connections and execution:</p> <pre><code># Create and run a pipeline\nsync = ls.Sync(\n    inputs=[webcam, mic],    # Data sources\n    outputs=[recorded]       # Final destinations\n)\nwith sync.compile() as runner:\n    runner.run()\n</code></pre> <p>What Sync does:</p> <ul> <li>Path Management: Tracks routes from inputs to outputs</li> <li>Validation: Ensures proper pipeline connections</li> <li>Execution: Coordinates data flow</li> <li>Resource Management: Handles cleanup and shutdown</li> </ul>"},{"location":"user-guide/core-concepts/#complete-example","title":"Complete Example","text":"<p>Here's how everything works together:</p> <pre><code>import livesync as ls\nfrom livesync import layers\n\n# Create input streams\nx1 = ls.WebcamInput(device_id=0, fps=30)\nx2 = ls.MicrophoneInput(sample_rate=44100)\n\n# Build processing pipeline\nh = layers.FpsControl(fps=15)(x1)\nu = layers.Merge([x1, x2], how=\"any\")\ny = layers.MediaRecorder(\"output.mp4\")(u)\n\n# Run pipeline\nsync = ls.Sync(inputs=[webcam, mic], outputs=[y])\nwith sync.compile() as runner:\n    runner.run()\n</code></pre> <p>This creates a pipeline where:</p> <ul> <li>Webcam generates frames (Input Stream)</li> <li>Frames flow through FPS control (Layer)</li> <li>Processed frames are recorded (Layer)</li> <li>Sync manages the entire flow</li> </ul> <p>This creates a pipeline that:</p> <ol> <li>Captures webcam frames and audio (Input Streams)</li> <li>Controls frame rate (Layer)</li> <li>Merges the streams (Layer)</li> <li>Records to an MP4 file (Layer)</li> </ol>"},{"location":"user-guide/core-concepts/#next-steps","title":"Next Steps","text":"<ul> <li>See complete Examples</li> </ul>"}]}